{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import csv\n",
    "from Metrics import spearman_correlation, KendallTau, PearsonCorrelation, RMSE\n",
    "from ReadData import readJsonData\n",
    "from LSTM_MLP_Model import LSTM_MLP_Model\n",
    "from GetDataTensors import getDataTensors\n",
    "from LossFunction import CustomLoss\n",
    "from Parameters import training_show_every as show_every, training_epochs as epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of videos:  50\n"
     ]
    }
   ],
   "source": [
    "csv_fields = ['epoch', 'train_loss', 'test_loss', 'person', 'person_p', 'spearman', 'spearman_p', 'rmse']\n",
    "csv_file_name = 'LSTM-MLP-Results.csv'\n",
    "\n",
    "csv_data_points_fields = ['real', 'predicted']\n",
    "csv_data_points_file_name = 'LSTM-MLP-Data-Points.csv'\n",
    "\n",
    "preprocessed_data, number_of_videos = readJsonData('./data.json')\n",
    "        \n",
    "print(\"Number of videos: \", number_of_videos)\n",
    "\n",
    "features_tensor = torch.tensor([item[3] for item in preprocessed_data])\n",
    "importance_tensor = torch.tensor([item[2] for item in preprocessed_data]).unsqueeze(1)\n",
    "\n",
    "prev_loss = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda: 1.15\n",
      "Epoch [1/1000], Loss: 2.8431, Test Loss: 3.0485, Pearson: 0.0786, Pearson p: 0.0000, Spearman: 0.0840, Spearman p: 0.0000, RMSE: 1.9469\n",
      "Epoch [25/1000], Loss: 2.5639, Test Loss: 2.8693, Pearson: 0.1341, Pearson p: 0.0000, Spearman: 0.1137, Spearman p: 0.0000, RMSE: 1.9005\n",
      "Epoch [50/1000], Loss: 2.3291, Test Loss: 2.6354, Pearson: 0.1194, Pearson p: 0.0000, Spearman: 0.1016, Spearman p: 0.0000, RMSE: 1.6368\n",
      "Epoch [75/1000], Loss: 1.2916, Test Loss: 1.3649, Pearson: 0.0953, Pearson p: 0.0000, Spearman: 0.0921, Spearman p: 0.0000, RMSE: 1.2275\n",
      "Epoch [100/1000], Loss: 0.7135, Test Loss: 0.9157, Pearson: 0.1008, Pearson p: 0.0000, Spearman: 0.1043, Spearman p: 0.0000, RMSE: 1.6668\n",
      "Epoch [125/1000], Loss: 0.6483, Test Loss: 0.8784, Pearson: 0.1193, Pearson p: 0.0000, Spearman: 0.1154, Spearman p: 0.0000, RMSE: 1.6585\n",
      "Epoch [150/1000], Loss: 0.6031, Test Loss: 0.8668, Pearson: 0.1254, Pearson p: 0.0000, Spearman: 0.1175, Spearman p: 0.0000, RMSE: 1.6387\n",
      "Epoch [175/1000], Loss: 0.5668, Test Loss: 0.8711, Pearson: 0.1215, Pearson p: 0.0000, Spearman: 0.1106, Spearman p: 0.0000, RMSE: 1.5959\n",
      "Overfitting...\n"
     ]
    }
   ],
   "source": [
    "with open(csv_file_name, mode='w', newline='') as csv_file, open(csv_data_points_file_name, mode='w', newline='') as csv_data_points_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow(csv_fields)\n",
    "    csv_data_points_writer = csv.writer(csv_data_points_file)\n",
    "    csv_data_points_writer.writerow(csv_data_points_fields)\n",
    "    for lmbda in [1.15 + (0.05 * i) for i in range(1)]:\n",
    "        csv_writer.writerow([f'Lambda: {lmbda}'])\n",
    "        print(f'Lambda: {lmbda}')\n",
    "        \n",
    "        model = LSTM_MLP_Model()\n",
    "\n",
    "        # Loss and optimizer\n",
    "        criterion = CustomLoss(lmbda)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "        # Get the data tensors\n",
    "        features_training_tensor, features_testing_tensor, importance_training_tensor, importance_testing_tensor = getDataTensors(features_tensor, importance_tensor)\n",
    "\n",
    "        # Train the model (dummy example, replace with your actual data)\n",
    "        features_training_tensor.requires_grad_()\n",
    "        \n",
    "        for epoch in range(1, epochs+1):\n",
    "            outputs = model(features_training_tensor)\n",
    "            targets = importance_training_tensor  # Targets are the same as input for reconstruction\n",
    "            loss = criterion(outputs.view(-1,1), targets)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                    test_outputs = model(features_testing_tensor)\n",
    "                    test_loss = criterion(test_outputs.view(-1,1), importance_testing_tensor)\n",
    "            \n",
    "            pearson, pearson_p = PearsonCorrelation(test_outputs.view(-1), importance_testing_tensor.view(-1))\n",
    "            spearman, spearman_p = spearman_correlation(test_outputs.view(-1), importance_testing_tensor.view(-1))\n",
    "            rmse = RMSE(test_outputs.view(-1), importance_testing_tensor.view(-1))\n",
    "        \n",
    "            csv_writer.writerow([epoch, loss.item(), test_loss.item(), pearson, pearson_p, spearman, spearman_p, rmse.item()])\n",
    "            \n",
    "            if epoch % show_every == 0 or epoch == 1:\n",
    "                print(f'Epoch [{epoch}/{epochs}], Loss: {loss.item():.4f}, Test Loss: {test_loss.item():.4f}, Pearson: {pearson:.4f}, Pearson p: {pearson_p:.4f}, Spearman: {spearman:.4f}, Spearman p: {spearman_p:.4f}, RMSE: {rmse:.4f}')\n",
    "                if test_loss.item() > prev_loss:\n",
    "                    print(\"Overfitting...\")\n",
    "                    break\n",
    "                else:\n",
    "                    prev_loss = test_loss.item()\n",
    "        \n",
    "        data_points = list(zip(importance_testing_tensor.view(-1).tolist(), test_outputs.view(-1).tolist()))\n",
    "        csv_data_points_writer.writerow(f'Lambda: {lmbda}')\n",
    "        csv_data_points_writer.writerows(data_points)\n",
    "        # Save the model\n",
    "        torch.save(model.state_dict(), f'LSTM-MLP-Lambda-{lmbda}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kendall: 0.0818, Kendall p: 0.0000\n"
     ]
    }
   ],
   "source": [
    "kendall, kendall_p = KendallTau(importance_testing_tensor.view(-1), test_outputs.view(-1))\n",
    "print(f'Kendall: {kendall:.4f}, Kendall p: {kendall_p:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
