{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import csv\n",
    "from Metrics import spearman_correlation, KendallTau, PearsonCorrelation, RMSE\n",
    "from ReadData import readJsonData\n",
    "from LSTM_MLP_Model import LSTM_MLP_Model\n",
    "from GetDataTensors import getDataTensors\n",
    "from LossFunction import CustomLoss\n",
    "from Parameters import training_show_every as show_every, training_epochs as epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of videos:  50\n"
     ]
    }
   ],
   "source": [
    "csv_fields = ['epoch', 'train_loss', 'test_loss', 'person', 'person_p', 'spearman', 'spearman_p', 'rmse']\n",
    "csv_file_name = 'LSTM-MLP-Results.csv'\n",
    "\n",
    "csv_data_points_fields = ['real', 'predicted']\n",
    "csv_data_points_file_name = 'LSTM-MLP-Data-Points.csv'\n",
    "\n",
    "preprocessed_data, number_of_videos = readJsonData('./data.json')\n",
    "        \n",
    "print(\"Number of videos: \", number_of_videos)\n",
    "\n",
    "features_tensor = torch.tensor([item[3] for item in preprocessed_data])\n",
    "importance_tensor = torch.tensor([item[2] for item in preprocessed_data]).unsqueeze(1)\n",
    "\n",
    "prev_loss = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda: 1.15\n",
      "Epoch [1/1000], Loss: 0.6025, Test Loss: 0.5456, Pearson: 0.1023, Pearson p: 0.0000, Spearman: 0.1017, Spearman p: 0.0000, RMSE: 1.9103\n",
      "Epoch [25/1000], Loss: 0.3506, Test Loss: 0.4755, Pearson: 0.1007, Pearson p: 0.0000, Spearman: 0.0772, Spearman p: 0.0000, RMSE: 1.7984\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15876\\3443915498.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\cuda_env\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \"\"\"\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\cuda_env\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with open(csv_file_name, mode='w', newline='') as csv_file, open(csv_data_points_file_name, mode='w', newline='') as csv_data_points_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow(csv_fields)\n",
    "    csv_data_points_writer = csv.writer(csv_data_points_file)\n",
    "    csv_data_points_writer.writerow(csv_data_points_fields)\n",
    "    for lmbda in [1.15 + (0.05 * i) for i in range(1)]:\n",
    "        csv_writer.writerow([f'Lambda: {lmbda}'])\n",
    "        print(f'Lambda: {lmbda}')\n",
    "        \n",
    "        model = LSTM_MLP_Model()\n",
    "\n",
    "        # Loss and optimizer\n",
    "        criterion = CustomLoss(lmbda)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "        # Get the data tensors\n",
    "        features_training_tensor, features_testing_tensor, importance_training_tensor, importance_testing_tensor = getDataTensors(features_tensor, importance_tensor)\n",
    "\n",
    "        # Train the model (dummy example, replace with your actual data)\n",
    "        features_training_tensor.requires_grad_()\n",
    "        \n",
    "        for epoch in range(1, epochs+1):\n",
    "            outputs = model(features_training_tensor)\n",
    "            targets = importance_training_tensor  # Targets are the same as input for reconstruction\n",
    "            loss = criterion(outputs.view(-1,1), targets)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                    test_outputs = model(features_testing_tensor)\n",
    "                    test_loss = criterion(test_outputs.view(-1,1), importance_testing_tensor)\n",
    "            \n",
    "            pearson, pearson_p = PearsonCorrelation(test_outputs.view(-1), importance_testing_tensor.view(-1))\n",
    "            spearman, spearman_p = spearman_correlation(test_outputs.view(-1), importance_testing_tensor.view(-1))\n",
    "            rmse = RMSE(test_outputs.view(-1), importance_testing_tensor.view(-1))\n",
    "        \n",
    "            csv_writer.writerow([epoch, loss.item(), test_loss.item(), pearson, pearson_p, spearman, spearman_p, rmse.item()])\n",
    "            \n",
    "            if epoch % show_every == 0 or epoch == 1:\n",
    "                print(f'Epoch [{epoch}/{epochs}], Loss: {loss.item():.4f}, Test Loss: {test_loss.item():.4f}, Pearson: {pearson:.4f}, Pearson p: {pearson_p:.4f}, Spearman: {spearman:.4f}, Spearman p: {spearman_p:.4f}, RMSE: {rmse:.4f}')\n",
    "                if test_loss.item() > prev_loss:\n",
    "                    print(\"Overfitting...\")\n",
    "                    break\n",
    "                else:\n",
    "                    prev_loss = test_loss.item()\n",
    "        \n",
    "        data_points = list(zip(importance_testing_tensor.view(-1).tolist(), test_outputs.view(-1).tolist()))\n",
    "        csv_data_points_writer.writerow(f'Lambda: {lmbda}')\n",
    "        csv_data_points_writer.writerows(data_points)\n",
    "        # Save the model\n",
    "        torch.save(model.state_dict(), f'LSTM-MLP-Lambda-{lmbda}.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
