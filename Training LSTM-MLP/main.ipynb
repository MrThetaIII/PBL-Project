{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import csv\n",
    "from Metrics import spearman_correlation, KendallTau, PearsonCorrelation, RMSE\n",
    "from ReadData import readJsonData\n",
    "from LSTM_MLP_Model import LSTM_MLP_Model\n",
    "from GetDataTensors import getDataTensors\n",
    "from LossFunction import CustomLoss\n",
    "from Parameters import training_show_every as show_every, training_epochs as epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of videos:  50\n"
     ]
    }
   ],
   "source": [
    "csv_fields = ['epoch', 'train_loss', 'test_loss', 'person', 'person_p', 'spearman', 'spearman_p', 'rmse']\n",
    "csv_file_name = 'LSTM-MLP-Results.csv'\n",
    "\n",
    "csv_data_points_fields = ['real', 'predicted']\n",
    "csv_data_points_file_name = 'LSTM-MLP-Data-Points.csv'\n",
    "\n",
    "preprocessed_data, number_of_videos = readJsonData('./data.json')\n",
    "        \n",
    "print(\"Number of videos: \", number_of_videos)\n",
    "\n",
    "features_tensor = torch.tensor([item[3] for item in preprocessed_data])\n",
    "importance_tensor = torch.tensor([item[2] for item in preprocessed_data]).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda: 1.15\n",
      "Epoch [1/1000], Loss: 2.8431, Test Loss: 3.0485, Pearson: 0.0786, Pearson p: 0.0000, Spearman: 0.0840, Spearman p: 0.0000, RMSE: 1.9469\n",
      "Epoch [25/1000], Loss: 2.5639, Test Loss: 2.8693, Pearson: 0.1341, Pearson p: 0.0000, Spearman: 0.1137, Spearman p: 0.0000, RMSE: 1.9005\n",
      "Epoch [50/1000], Loss: 2.3291, Test Loss: 2.6354, Pearson: 0.1194, Pearson p: 0.0000, Spearman: 0.1016, Spearman p: 0.0000, RMSE: 1.6368\n",
      "Epoch [75/1000], Loss: 1.2916, Test Loss: 1.3649, Pearson: 0.0953, Pearson p: 0.0000, Spearman: 0.0921, Spearman p: 0.0000, RMSE: 1.2275\n",
      "Epoch [100/1000], Loss: 0.7135, Test Loss: 0.9157, Pearson: 0.1008, Pearson p: 0.0000, Spearman: 0.1043, Spearman p: 0.0000, RMSE: 1.6668\n",
      "Epoch [125/1000], Loss: 0.6483, Test Loss: 0.8784, Pearson: 0.1193, Pearson p: 0.0000, Spearman: 0.1154, Spearman p: 0.0000, RMSE: 1.6585\n",
      "Epoch [150/1000], Loss: 0.6031, Test Loss: 0.8668, Pearson: 0.1254, Pearson p: 0.0000, Spearman: 0.1175, Spearman p: 0.0000, RMSE: 1.6387\n",
      "Epoch [175/1000], Loss: 0.5668, Test Loss: 0.8711, Pearson: 0.1215, Pearson p: 0.0000, Spearman: 0.1106, Spearman p: 0.0000, RMSE: 1.5959\n",
      "Overfitting...\n"
     ]
    }
   ],
   "source": [
    "with open(csv_file_name, mode='w', newline='') as csv_file, open(csv_data_points_file_name, mode='w', newline='') as csv_data_points_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow(csv_fields)\n",
    "    csv_data_points_writer = csv.writer(csv_data_points_file)\n",
    "    csv_data_points_writer.writerow(csv_data_points_fields)\n",
    "    for lmbda in [1.15 + (0.05 * i) for i in range(1)]:\n",
    "        csv_writer.writerow([f'Lambda: {lmbda}'])\n",
    "        print(f'Lambda: {lmbda}')\n",
    "        \n",
    "        model = LSTM_MLP_Model()\n",
    "\n",
    "        # Loss and optimizer\n",
    "        criterion = CustomLoss(lmbda)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "        # Get the data tensors\n",
    "        features_training_tensor, features_testing_tensor, importance_training_tensor, importance_testing_tensor = getDataTensors(features_tensor, importance_tensor)\n",
    "\n",
    "        # Train the model (dummy example, replace with your actual data)\n",
    "        features_training_tensor.requires_grad_()\n",
    "        \n",
    "        for epoch in range(1, epochs+1):\n",
    "            outputs = model(features_training_tensor)\n",
    "            targets = importance_training_tensor  # Targets are the same as input for reconstruction\n",
    "            loss = criterion(outputs.view(-1,1), targets)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                    test_outputs = model(features_testing_tensor)\n",
    "                    test_loss = criterion(test_outputs.view(-1,1), importance_testing_tensor)\n",
    "            \n",
    "            pearson, pearson_p = PearsonCorrelation(test_outputs.view(-1), importance_testing_tensor.view(-1))\n",
    "            spearman, spearman_p = spearman_correlation(test_outputs.view(-1), importance_testing_tensor.view(-1))\n",
    "            rmse = RMSE(test_outputs.view(-1), importance_testing_tensor.view(-1))\n",
    "        \n",
    "            csv_writer.writerow([epoch, loss.item(), test_loss.item(), pearson, pearson_p, spearman, spearman_p, rmse.item()])\n",
    "            \n",
    "            if epoch % show_every == 0 or epoch == 1:\n",
    "                print(f'Epoch [{epoch}/{epochs}], Loss: {loss.item():.4f}, Test Loss: {test_loss.item():.4f}, Pearson: {pearson:.4f}, Pearson p: {pearson_p:.4f}, Spearman: {spearman:.4f}, Spearman p: {spearman_p:.4f}, RMSE: {rmse:.4f}')\n",
    "                if test_loss.item() > prev_loss:\n",
    "                    print(\"Overfitting...\")\n",
    "                    break\n",
    "                else:\n",
    "                    prev_loss = test_loss.item()\n",
    "        \n",
    "        data_points = list(zip(importance_testing_tensor.view(-1).tolist(), test_outputs.view(-1).tolist()))\n",
    "        csv_data_points_writer.writerow(f'Lambda: {lmbda}')\n",
    "        csv_data_points_writer.writerows(data_points)\n",
    "        # Save the model\n",
    "        torch.save(model.state_dict(), f'LSTM-MLP-Lambda-{lmbda}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kendall: 0.0818, Kendall p: 0.0000\n"
     ]
    }
   ],
   "source": [
    "kendall, kendall_p = KendallTau(importance_testing_tensor.view(-1), test_outputs.view(-1))\n",
    "print(f'Kendall: {kendall:.4f}, Kendall p: {kendall_p:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda: 0.5, Mu: 0.5\n",
      "1, 10, 20, 30, Overfitting...\n",
      "Epoch [30/1000], Loss: 0.4694, Test Loss: 0.6750, Pearson: 0.0855, Pearson p: 0.0000, Spearman: 0.0788, Spearman p: 0.0000, RMSE: 1.4368\n",
      "Lambda: 0.5, Mu: 1.0\n",
      "1, 10, 20, 30, Overfitting...\n",
      "Epoch [30/1000], Loss: 0.6161, Test Loss: 1.0462, Pearson: 0.0813, Pearson p: 0.0000, Spearman: 0.0590, Spearman p: 0.0001, RMSE: 1.4612\n",
      "Lambda: 0.5, Mu: 1.5\n",
      "1, 10, 20, 30, 40, Overfitting...\n",
      "Epoch [40/1000], Loss: 0.6497, Test Loss: 1.3829, Pearson: 0.0861, Pearson p: 0.0000, Spearman: 0.0609, Spearman p: 0.0000, RMSE: 1.4031\n",
      "Lambda: 0.5, Mu: 2.0\n",
      "1, 10, 20, 30, 40, Overfitting...\n",
      "Epoch [40/1000], Loss: 0.7401, Test Loss: 1.8315, Pearson: 0.0724, Pearson p: 0.0000, Spearman: 0.0456, Spearman p: 0.0018, RMSE: 1.3589\n",
      "Lambda: 1.0, Mu: 0.5\n",
      "1, 10, 20, 30, 40, Overfitting...\n",
      "Epoch [40/1000], Loss: 0.4479, Test Loss: 0.7029, Pearson: 0.0711, Pearson p: 0.0000, Spearman: 0.0649, Spearman p: 0.0000, RMSE: 1.4765\n",
      "Lambda: 1.0, Mu: 1.0\n",
      "1, 10, 20, 30, 40, Overfitting...\n",
      "Epoch [40/1000], Loss: 0.5991, Test Loss: 1.0888, Pearson: 0.0717, Pearson p: 0.0000, Spearman: 0.0548, Spearman p: 0.0002, RMSE: 1.4443\n",
      "Lambda: 1.0, Mu: 1.5\n",
      "1, 10, 20, 30, 40, Overfitting...\n",
      "Epoch [40/1000], Loss: 0.7212, Test Loss: 1.4861, Pearson: 0.0679, Pearson p: 0.0000, Spearman: 0.0450, Spearman p: 0.0020, RMSE: 1.4404\n",
      "Lambda: 1.0, Mu: 2.0\n",
      "1, 10, 20, 30, 40, Overfitting...\n",
      "Epoch [40/1000], Loss: 0.8415, Test Loss: 1.8055, Pearson: 0.0762, Pearson p: 0.0000, Spearman: 0.0569, Spearman p: 0.0001, RMSE: 1.4571\n",
      "Lambda: 1.5, Mu: 0.5\n",
      "1, 10, 20, 30, 40, 50, Overfitting...\n",
      "Epoch [50/1000], Loss: 0.4472, Test Loss: 0.6746, Pearson: 0.0905, Pearson p: 0.0000, Spearman: 0.0870, Spearman p: 0.0000, RMSE: 1.5279\n",
      "Lambda: 1.5, Mu: 1.0\n",
      "1, 10, 20, 30, 40, Overfitting...\n",
      "Epoch [40/1000], Loss: 0.6063, Test Loss: 1.1101, Pearson: 0.0665, Pearson p: 0.0000, Spearman: 0.0515, Spearman p: 0.0004, RMSE: 1.4693\n",
      "Lambda: 1.5, Mu: 1.5\n",
      "1, 10, 20, 30, 40, Overfitting...\n",
      "Epoch [40/1000], Loss: 0.7662, Test Loss: 1.4725, Pearson: 0.0719, Pearson p: 0.0000, Spearman: 0.0555, Spearman p: 0.0001, RMSE: 1.4661\n",
      "Lambda: 1.5, Mu: 2.0\n",
      "1, 10, 20, 30, 40, Overfitting...\n",
      "Epoch [40/1000], Loss: 0.8989, Test Loss: 1.8354, Pearson: 0.0737, Pearson p: 0.0000, Spearman: 0.0542, Spearman p: 0.0002, RMSE: 1.4691\n",
      "Lambda: 2.0, Mu: 0.5\n",
      "1, 10, 20, 30, 40, Overfitting...\n",
      "Epoch [40/1000], Loss: 0.5146, Test Loss: 0.6678, Pearson: 0.1051, Pearson p: 0.0000, Spearman: 0.1063, Spearman p: 0.0000, RMSE: 1.5862\n",
      "Lambda: 2.0, Mu: 1.0\n",
      "1, 10, 20, 30, 40, Overfitting...\n",
      "Epoch [40/1000], Loss: 0.6346, Test Loss: 1.0401, Pearson: 0.0886, Pearson p: 0.0000, Spearman: 0.0796, Spearman p: 0.0000, RMSE: 1.4785\n",
      "Lambda: 2.0, Mu: 1.5\n",
      "1, 10, 20, 30, 40, Overfitting...\n",
      "Epoch [40/1000], Loss: 0.7636, Test Loss: 1.3845, Pearson: 0.0986, Pearson p: 0.0000, Spearman: 0.0807, Spearman p: 0.0000, RMSE: 1.4257\n",
      "Lambda: 2.0, Mu: 2.0\n",
      "1, 10, 20, 30, 40, Overfitting...\n",
      "Epoch [40/1000], Loss: 0.9437, Test Loss: 1.8890, Pearson: 0.0677, Pearson p: 0.0000, Spearman: 0.0479, Spearman p: 0.0010, RMSE: 1.4700\n"
     ]
    }
   ],
   "source": [
    "for lmbda in [0.5 + (0.5 * i) for i in range(4)]:\n",
    "    for mu in [0.5 + (0.5 * i) for i in range(4)]:\n",
    "        print(f'Lambda: {lmbda}, Mu: {mu}')\n",
    "        with open(f'./VsLossParameters/Points_lambda_{lmbda}_mu_{mu}.csv', mode='w', newline='') as csv_file, open(f'./VsLossParameters/Results_lambda_{lmbda}_mu_{mu}.csv', mode='w', newline='') as csv_data_points_file:\n",
    "            csv_writer = csv.writer(csv_file)\n",
    "            csv_writer.writerow(csv_fields)\n",
    "            csv_data_points_writer = csv.writer(csv_data_points_file)\n",
    "            csv_data_points_writer.writerow(csv_data_points_fields)\n",
    "\n",
    "            pearson = 0\n",
    "            rmse = 3\n",
    "            \n",
    "            torch.manual_seed(6)\n",
    "            \n",
    "            prev_loss = 1000000\n",
    "            model = LSTM_MLP_Model()\n",
    "\n",
    "            # Loss and optimizer\n",
    "            criterion = CustomLoss(lmbda, mu)\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        \n",
    "            # Get the data tensors\n",
    "            features_training_tensor, features_testing_tensor, importance_training_tensor, importance_testing_tensor = getDataTensors(features_tensor, importance_tensor)\n",
    "\n",
    "            # Train the model (dummy example, replace with your actual data)\n",
    "            features_training_tensor.requires_grad_()\n",
    "            \n",
    "            for epoch in range(1, epochs+1):\n",
    "                outputs = model(features_training_tensor)\n",
    "                targets = importance_training_tensor  # Targets are the same as input for reconstruction\n",
    "                loss = criterion(outputs.view(-1,1), targets)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    test_outputs = model(features_testing_tensor)\n",
    "                    test_loss = criterion(test_outputs.view(-1,1), importance_testing_tensor)\n",
    "                \n",
    "                pearson, pearson_p = PearsonCorrelation(test_outputs.view(-1), importance_testing_tensor.view(-1))\n",
    "                spearman, spearman_p = spearman_correlation(test_outputs.view(-1), importance_testing_tensor.view(-1))\n",
    "                rmse = RMSE(test_outputs.view(-1), importance_testing_tensor.view(-1))\n",
    "            \n",
    "                csv_writer.writerow([epoch, loss.item(), test_loss.item(), pearson, pearson_p, spearman, spearman_p, rmse.item()])\n",
    "                \n",
    "                if epoch % show_every == 0 or epoch == 1:\n",
    "                    #if epoch == 1: print(f'Epoch [{epoch}/{epochs}], Loss: {loss.item():.4f}, Test Loss: {test_loss.item():.4f}, Pearson: {pearson:.4f}, Pearson p: {pearson_p:.4f}, Spearman: {spearman:.4f}, Spearman p: {spearman_p:.4f}, RMSE: {rmse:.4f}')\n",
    "                    print(f\"{epoch}\", end=\", \")\n",
    "                    if test_loss.item() > prev_loss:\n",
    "                        print(\"Overfitting...\")\n",
    "                        break\n",
    "                    else:\n",
    "                        prev_loss = test_loss.item()\n",
    "            print(f'Epoch [{epoch}/{epochs}], Loss: {loss.item():.4f}, Test Loss: {test_loss.item():.4f}, Pearson: {pearson:.4f}, Pearson p: {pearson_p:.4f}, Spearman: {spearman:.4f}, Spearman p: {spearman_p:.4f}, RMSE: {rmse:.4f}')\n",
    "            data_points = list(zip(importance_testing_tensor.view(-1).tolist(), test_outputs.view(-1).tolist()))\n",
    "            csv_data_points_writer.writerows(data_points)\n",
    "            # Save the model\n",
    "            torch.save(model.state_dict(), f'./VsLossParameters/Model_lambda_{lmbda}_mu_{mu}.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
